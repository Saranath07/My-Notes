[
  {
    "objectID": "pages/DL/IntroDL.html",
    "href": "pages/DL/IntroDL.html",
    "title": "Backpropogation",
    "section": "",
    "text": "Backpropogation is a technique which is used to find the gradients of each layer with respect to the loss. We can write our output function as:\n\\[\n\\hat{y}_i = \\hat{f}(x_i) = O(W_3 \\ g(W_2 \\ g(W_1 x_i + b_1) + b_2) + b_3)\n\\]\nThis is when we have 3 inputs, 2 hidden layers with 3 neurons in each and 1 output layer.\nWe use the optimization algorithm Gradient Descent which can be used to traverse the loss function and get into the local minima.\nThe update rule goes like this:\n\\[\n\\theta_{t+1} = \\theta_{t} - \\eta \\nabla_{\\theta}\\mathcal{L}(\\theta)\n\\]\nwhere \\[\n\\begin{align*}\n\\theta  &  :     \\text{Parameters} \\\\\n\\eta & :  \\text{Learning Rate} \\\\\n\\nabla_{\\theta}\\mathcal{L}(\\theta) & : \\text{Gradient of loss function with respect to the parameters}.\n\\end{align*}\n\\]\nAs we have more parameters and functions, computation of gradient with respect to the parameters i.e.Â \\(\\nabla_{\\theta}\\mathcal{L}(\\theta)\\) is not straight forward.\nSo we depend on chain rule to get the solution.\nLet us try to compute just the loss with respect to \\(1\\) parameter.\n\\[\n\\dfrac{\\partial \\mathcal{L}(\\theta)}{\\partial W_{111}} = \\dfrac{\\partial \\mathcal{L}(\\theta)}{\\partial \\hat{y}}\\dfrac{\\partial \\hat{y}}{\\partial a_{L11}}\\dfrac{\\partial a_{L11}}{\\partial h_{21}}\\dfrac{\\partial h_{21}}{\\partial a_{21}}\\dfrac{\\partial a_{21}}{\\partial h_{11}}\\dfrac{\\partial h_{11}}{\\partial a_{11}}\\dfrac{\\partial a_{11}}{\\partial W_{111}}\n\\]\nBefore actually understanding this equation, let us see what each term refers to.\n\\[\n\\begin{align*}\n\\mathcal{L}(\\theta) & : \\text{Loss function with respect to } \\theta \\\\\n\\hat{y} & : \\text{Predicted } y \\\\\nh & : \\text{Activation layer} \\\\\na & : \\text{Pre-activation layer}\\\\\nW & : \\text{Weights} \\\\\nb & : \\text{Biases}\n\\end{align*}\n\\]\nFirstly, we have to forward propogate through layers. First of all we have to initialize \\(W_1\\).\nSimilarly we will do for other neurons.\nSo, now let us try to write the equations for them.\nFor the input layer to the hidden layer we have,\nFirst, we compute the values of pre-activation layer \\(a_i\\).\nTherefore, \\[\na_1 = W_1  \\textbf{x} + b_1\n\\] where \\(\\textbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\vdots \\\\ x_n \\end{bmatrix}, \\textbf{b} = \\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n \\end{bmatrix}\\) and \\(W_1 = \\begin{bmatrix} w_{11} & w_{12} & \\ldots & w_{1n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ w_{1n} & w_{2n} & \\ldots & w_{nn}  \\end{bmatrix}\\)\nHere we have \\(\\textbf{x} \\in \\mathbb{R}^n\\) and \\(W \\in \\mathbb{R}^{n \\times n}\\). (Note that all the layers have same number of neurons. If we have \\(m\\) neurons in hidden layer and \\(n\\) neurons in input layer, then we will have our weight matrix dimensions as \\(\\mathbb{R}^{m \\times n}\\))\nNow we have got values for the pre-activation layer. Now we have to intoduce the activation layer will be applied to every value in the pre-activation vector.\n\\[\nh_1 = g(a_1)\n\\]\nThen we will be performng this action for every layer.\nNow, as we have just 1 hidden layer in our example, we need to get the values for the output.\nNow we will use an output function and pass our hidden layer inputs to get the outputs. (This can potentially vary from the activation function.)\n\\[\n\\hat{y} = O(h_1)\n\\]\nNow let us try to take an example for \\(g\\) and \\(O\\) functions.\nIn this example we will use \\[\n\\begin{align*}\ng(x_i) & = \\dfrac{1}{1 + e^{-x_i}} \\\\\\\\\nO(x_i) & = \\dfrac{e^{x_i}}{\\sum_{j = 1}^{n}{x_j}}\n\\end{align*}\n\\] We usually call \\(g(x)\\) as sigmoid function adn \\(O(x)\\) as softmax function\nSo, we will use python to code them out.\nNow we have to decide upon the loss function. Two best candidates for the loss functions are : Mean squared Loss and Cross Entropy Loss.\nMean Squared loss is generally defined as: \\[\nMSE(\\hat{y}, y)  = \\dfrac{1}{n}(\\hat{y} - y)^2\n\\]\nand Cross entropy loss can be given as \\[\nCrossEntropy(\\hat{y}, y) = -y\\log(\\hat{y})\n\\]\nWe will use cross entropy for this example and then we will also see a code for implementing mean squared loss\nGenerally we follow this table\nSo, we will now use the backpropogation to update the parameters so that we can put them in our Gradient Descent Algorithm.\nFirst with the formula above, we can code the forward propogation.\nNow, we can forward propogate.",
    "crumbs": [
      "Deep Learning",
      "Backpropogation"
    ]
  },
  {
    "objectID": "pages/MAB/IntroMAB.html",
    "href": "pages/MAB/IntroMAB.html",
    "title": "Introduction to Multi-Armed Bandits",
    "section": "",
    "text": "This page is for MAB"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Notes",
    "section": "",
    "text": "I put the course notes for my own easy perusal.\nprint(\"Hello World\")"
  },
  {
    "objectID": "pages/LLM/Week5.html",
    "href": "pages/LLM/Week5.html",
    "title": "Week 5 LLM",
    "section": "",
    "text": "Week 5 LLM\nWeek 5 of the course LLM"
  },
  {
    "objectID": "pages/DL/IntroDL.html#talking-to-the-output-layer",
    "href": "pages/DL/IntroDL.html#talking-to-the-output-layer",
    "title": "Backpropogation",
    "section": "Talking to the Output Layer",
    "text": "Talking to the Output Layer\nSo we should calculate the loss with respect to the output layer.\n\\[\n\\dfrac{\\partial \\mathcal{L}(\\theta)}{\\partial \\hat{y}} = \\dfrac{\\partial \\ Cross Entropy (y, \\hat{y})}{\\partial \\hat{y}}\n\\]\nImagine we have a binary classification problem which just outputs \\(0\\) or \\(1\\). So our Cross entropy function can be given as : \\[\nCrossEntropy(y, \\hat{y}) = -\\log{\\hat{y}}\n\\]\nNow we have to calculate the partial derivative. So we can write, \\[\n\\begin{align*}\n\\dfrac{\\partial (-\\log(\\hat{y}))}{\\partial \\hat{y}} & = \\dfrac{\\mathbb{I}_l}{\\hat{y}}\n\\end{align*}\n\\] We know that \\(\\hat{y}\\) is a one hot vector as we will have only one class to be true. So \\(\\mathbb{I}_l\\) is the vector where it has \\(1\\) at \\(l^{th}\\) position and rest are all \\(0\\)s",
    "crumbs": [
      "Deep Learning",
      "Backpropogation"
    ]
  }
]